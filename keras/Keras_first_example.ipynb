{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Keras Example\n",
    "\n",
    "January 29, 2017\n",
    "\n",
    "Pan Chao\n",
    "\n",
    "This example fits a single-input NN model with 2 classes (binary). We will do:\n",
    "\n",
    "- Simulate data with binary label\n",
    "- Train with zero layer NN (only has input and output layer)\n",
    "- The sigmoid loss function is applied on the output of the NN for classification\n",
    "\n",
    "# Detail\n",
    "\n",
    "- The input $x_i$ is a 784-dimensional vector\n",
    "- The NN is trained to learn the linear function $f(x) = \\beta^\\top x + \\beta_0$\n",
    "- Each output $f(x_i)$ is transformed by a sigmoid function $\\sigma(f(x_i)) = \\frac{1}{1 + e^{-f(x_i)}}$\n",
    "- Each data point is classified according to if $\\sigma(f(x_i)) \\geq 0$ or not\n",
    "- This is exactly the same as a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=784, activation='sigmoid', bias=True))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 784))\n",
    "labels = np.random.randint(2, size=(1000, 1))  # 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.7417 - acc: 0.4790     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.7208 - acc: 0.5040     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.7135 - acc: 0.5000     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.7081 - acc: 0.5260     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6968 - acc: 0.5410     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6920 - acc: 0.5450     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6827 - acc: 0.5670     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6757 - acc: 0.5810     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6554 - acc: 0.6150     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6646 - acc: 0.6000     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a3e9e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(data, labels, nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the model structure \n",
    "# Note: need pydot 1.1.0 package: pip install pydot==1.1.0\n",
    "\n",
    "from keras.utils.visualize_util import plot\n",
    "\n",
    "plot(model, 'model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 1)             785         dense_input_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show summary of the trained model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 784 coefficients, one for each input dimension, and 1 bias. Thus the total number of parameters is 785."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
